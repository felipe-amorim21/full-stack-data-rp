# -*- coding: utf-8 -*-
"""avaliacao_rp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16V58Zs7LW4PtN0-wRkJhS0iO-s9VIMv2
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, roc_curve
import joblib
import os

import pandas as pd
import numpy as np
from scipy.special import expit

# Semente para reprodutibilidade
np.random.seed(42)
n_samples = 1000

data = {
    'idade': np.random.randint(17, 30, n_samples),
    'sexo': np.random.choice(['M', 'F'], n_samples),
    'tipo_escola_medio': np.random.choice(['publica', 'privada'], n_samples),
    'nota_enem': np.random.normal(600, 100, n_samples),
    'renda_familiar': np.random.normal(3, 1.5, n_samples),
    'trabalha': np.random.choice([0, 1], n_samples),
    'horas_trabalho_semana': np.random.choice([0, 20, 30, 40], n_samples),
    'reprovacoes_1_sem': np.random.choice([0, 1, 2, 3], n_samples),
    'bolsista': np.random.choice([0, 1], n_samples),
    'distancia_campus_km': np.random.uniform(1, 50, n_samples),
}

df = pd.DataFrame(data)

# 2. Criação da Target (Evasão) com CORRELAÇÃO
# Criamos um "Score de Risco" linear.
# Pesos positivos (+) aumentam o risco de evasão.
# Pesos negativos (-) diminuem o risco (protegem o aluno).

risk_score = (
    - 0.02 * df['nota_enem']             # Nota alta protege contra evasão
    + 0.90 * df['reprovacoes_1_sem']     # Reprovação aumenta MUITO o risco
    + 0.04 * df['distancia_campus_km']   # Longe aumenta o risco
    + 0.03 * df['horas_trabalho_semana'] # Trabalhar muito aumenta o risco levemente
    - 0.40 * df['renda_familiar']        # Renda mais alta protege levemente
    + np.random.normal(0, 1.5, n_samples) # Ruído aleatório (para o modelo não ficar 100% perfeito)
)


probabilidade_evasao = expit(risk_score - risk_score.mean())


df['evasao_ate_1ano'] = [1 if p > np.random.rand() else 0 for p in probabilidade_evasao]


print("Distribuição da Evasão:")
print(df['evasao_ate_1ano'].value_counts(normalize=True))
print("\nDados gerados com sucesso!")

X = df.drop('evasao_ate_1ano', axis=1)
y = df['evasao_ate_1ano']

numeric_features = ['idade', 'nota_enem', 'renda_familiar', 'horas_trabalho_semana', 'reprovacoes_1_sem', 'distancia_campus_km']
categorical_features = ['sexo', 'tipo_escola_medio']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])


clf = Pipeline(steps=[('preprocessor', preprocessor),
                      ('classifier', LogisticRegression())])


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)


clf.fit(X_train, y_train)


y_pred = clf.predict(X_test)
y_proba = clf.predict_proba(X_test)[:, 1]

print(f"Acurácia: {accuracy_score(y_test, y_pred):.2f}")
print(f"Recall: {recall_score(y_test, y_pred):.2f}")
print(f"Precision: {precision_score(y_test, y_pred):.2f}")
print(f"F1 Score: {f1_score(y_test, y_pred):.2f}")
print(f"AUC-ROC: {roc_auc_score(y_test, y_proba):.2f}")

joblib.dump(clf, 'full_stack_data_rp/model/logistic_model.pkl')
print("Modelo salvo")